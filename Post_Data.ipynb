{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe14d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from praw.models import MoreComments\n",
    "\n",
    "# #URL to access the app needed to scrape the data off the Berkeley subreddit\n",
    "# # https://www.reddit.com/prefs/apps\n",
    "\n",
    "#This is the tutorial I used to set up the web scraping using PRAW\n",
    "#https://www.geeksforgeeks.org/python/scraping-reddit-using-python/\n",
    "\n",
    "# #PLAN\n",
    "# #Scrape the data off the Berkeley subreddit about consulting clubs\n",
    "# #Organize that data using the pandas library\n",
    "# #Create chatbot that utilizes natural language processing that will give users feedback\n",
    "# #about each consulting club here at Berkeley. \n",
    "\n",
    "reddit_read_only = praw.Reddit(client_id = \"QlBfNfxQ3e_MGP9RkaOQig\",\n",
    "                               client_secret = \"SpLjOwYdQPU4z1wqcXBjVl_7DnUIZg\",\n",
    "                               user_agent = \"Berkeley_Consulting\")\n",
    "\n",
    "subreddit = reddit_read_only.subreddit(\"berkeley\")\n",
    "\n",
    "# df1 = pd.DataFrame({\n",
    "#     'post_id': ['p1', 'p2', 'p3'],\n",
    "#     'title': ['Title A', 'Title B', 'Title C'],\n",
    "#     'author': ['user1', 'user2', 'user3']\n",
    "# })\n",
    "\n",
    "# df2 = pd.DataFrame({\n",
    "#     'comment_id': ['c1', 'c2', 'c3', 'c4', 'c5'],\n",
    "#     'post_id': ['p1', 'p1', 'p2', 'p2', 'p4'],  # Note: p4 doesn't exist in df1\n",
    "#     'comment': ['Great post!', 'Thanks!', 'Interesting', 'I agree', 'Nice!']\n",
    "# })\n",
    "# outer_merged = df1.merge(df2, on='post_id', how='outer')\n",
    "# print(outer_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "178c2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "consulting_posts = subreddit.search('consulting')\n",
    "\n",
    "posts_dict = {'Title': [], 'Post Text': [], 'ID': [], 'Score': [], 'Total Comments': [], 'Post URL': []}\n",
    "comments_dict = {'Comment': [], 'Score': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ecf18af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Post Text</th>\n",
       "      <th>ID</th>\n",
       "      <th>Score</th>\n",
       "      <th>Total Comments</th>\n",
       "      <th>Post URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asian monoculture in consulting clubs</td>\n",
       "      <td>Over the past month on this subreddit there ha...</td>\n",
       "      <td>16o5u8z</td>\n",
       "      <td>267</td>\n",
       "      <td>112</td>\n",
       "      <td>https://www.reddit.com/r/berkeley/comments/16o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are consulting clubs actually looking for?</td>\n",
       "      <td>I am an incoming freshman at Haas next year an...</td>\n",
       "      <td>1kvi9jt</td>\n",
       "      <td>43</td>\n",
       "      <td>55</td>\n",
       "      <td>https://www.reddit.com/r/berkeley/comments/1kv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tech PM blocks all “.berkeley.edu” e-mails bc ...</td>\n",
       "      <td>Consulting clubs making us look bad smh</td>\n",
       "      <td>19d8ceg</td>\n",
       "      <td>563</td>\n",
       "      <td>43</td>\n",
       "      <td>https://i.redd.it/em6d28vzh2ec1.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rejected from consulting club after having bee...</td>\n",
       "      <td>titles kinda self explanatory lol. didn’t even...</td>\n",
       "      <td>1na99k8</td>\n",
       "      <td>76</td>\n",
       "      <td>22</td>\n",
       "      <td>https://www.reddit.com/r/berkeley/comments/1na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why are some of these Business/Consulting Club...</td>\n",
       "      <td>My friend and I were enjoying dinner in the so...</td>\n",
       "      <td>16jsy19</td>\n",
       "      <td>367</td>\n",
       "      <td>55</td>\n",
       "      <td>https://www.reddit.com/r/berkeley/comments/16j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>another bear rejected by consulting clubs</td>\n",
       "      <td>I know it's just a club but man I wanna cry i ...</td>\n",
       "      <td>piudil</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.reddit.com/r/berkeley/comments/piu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>There are 150-odd chapters of Chinese Students...</td>\n",
       "      <td></td>\n",
       "      <td>69fs7e</td>\n",
       "      <td>51</td>\n",
       "      <td>22</td>\n",
       "      <td>https://www.nytimes.com/2017/05/04/us/chinese-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NEW! - Stress Management Consultations</td>\n",
       "      <td>Stress Management Consultations at the UHS Car...</td>\n",
       "      <td>zdf1h4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/berkeley/comments/zdf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Made it to a Consulting Club’s Final Round Int...</td>\n",
       "      <td>I’m not happy about getting rejected but I did...</td>\n",
       "      <td>sjnb6y</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>https://www.reddit.com/r/berkeley/comments/sjn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Advice on applying to consulting clubs</td>\n",
       "      <td>I plan to apply to several consulting and fina...</td>\n",
       "      <td>x2t0gr</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.reddit.com/r/berkeley/comments/x2t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0               Asian monoculture in consulting clubs   \n",
       "1     What are consulting clubs actually looking for?   \n",
       "2   Tech PM blocks all “.berkeley.edu” e-mails bc ...   \n",
       "3   Rejected from consulting club after having bee...   \n",
       "4   Why are some of these Business/Consulting Club...   \n",
       "..                                                ...   \n",
       "95          another bear rejected by consulting clubs   \n",
       "96  There are 150-odd chapters of Chinese Students...   \n",
       "97             NEW! - Stress Management Consultations   \n",
       "98  Made it to a Consulting Club’s Final Round Int...   \n",
       "99             Advice on applying to consulting clubs   \n",
       "\n",
       "                                            Post Text       ID  Score  \\\n",
       "0   Over the past month on this subreddit there ha...  16o5u8z    267   \n",
       "1   I am an incoming freshman at Haas next year an...  1kvi9jt     43   \n",
       "2             Consulting clubs making us look bad smh  19d8ceg    563   \n",
       "3   titles kinda self explanatory lol. didn’t even...  1na99k8     76   \n",
       "4   My friend and I were enjoying dinner in the so...  16jsy19    367   \n",
       "..                                                ...      ...    ...   \n",
       "95  I know it's just a club but man I wanna cry i ...   piudil     31   \n",
       "96                                                      69fs7e     51   \n",
       "97  Stress Management Consultations at the UHS Car...   zdf1h4      7   \n",
       "98  I’m not happy about getting rejected but I did...   sjnb6y      3   \n",
       "99  I plan to apply to several consulting and fina...   x2t0gr      0   \n",
       "\n",
       "    Total Comments                                           Post URL  \n",
       "0              112  https://www.reddit.com/r/berkeley/comments/16o...  \n",
       "1               55  https://www.reddit.com/r/berkeley/comments/1kv...  \n",
       "2               43               https://i.redd.it/em6d28vzh2ec1.jpeg  \n",
       "3               22  https://www.reddit.com/r/berkeley/comments/1na...  \n",
       "4               55  https://www.reddit.com/r/berkeley/comments/16j...  \n",
       "..             ...                                                ...  \n",
       "95               7  https://www.reddit.com/r/berkeley/comments/piu...  \n",
       "96              22  https://www.nytimes.com/2017/05/04/us/chinese-...  \n",
       "97               0  https://www.reddit.com/r/berkeley/comments/zdf...  \n",
       "98               6  https://www.reddit.com/r/berkeley/comments/sjn...  \n",
       "99               2  https://www.reddit.com/r/berkeley/comments/x2t...  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for post in consulting_posts:\n",
    "    #The title of the post\n",
    "    posts_dict['Title'].append(post.title)\n",
    "    #The text inside of the post\n",
    "    posts_dict['Post Text'].append(post.selftext)\n",
    "    #Unique ID of each post\n",
    "    posts_dict['ID'].append(post.id)\n",
    "    #The scoure of a post\n",
    "    posts_dict['Score'].append(post.score)\n",
    "    #Total number of comments inside the post\n",
    "    posts_dict['Total Comments'].append(post.num_comments)\n",
    "    #URL of each post\n",
    "    posts_dict['Post URL'].append(post.url)\n",
    "\n",
    "consulting_club_posts = pd.DataFrame(posts_dict)\n",
    "# print(consulting_club_posts)\n",
    "consulting_club_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d1eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to figure out a way to get the URL of each and every post\n",
    "for i in posts_dict['Post URL']:\n",
    "    if 'comments' in i:\n",
    "        submission = reddit_read_only.submission(url = i)\n",
    "    else:\n",
    "        continue\n",
    "    for comment in submission.comments:\n",
    "        if len(comment.body) < 20:\n",
    "            continue\n",
    "        comments_dict['Comment'].append(comment.body)\n",
    "        comments_dict['Score'].append(comment.score)\n",
    "\n",
    "# print(post_comments[0]) #This only prints one comment right now for one URL. Need to get as many comments as possible for one given URL.\n",
    "\n",
    "comments_df = pd.DataFrame(comments_dict)\n",
    "comments_df\n",
    "\n",
    "#Generate the CSV file that contains all the posts about Berkeley clubs\n",
    "# comments_df.to_csv('my_dataframe.csv', index=False) # index=False prevents writing the DataFrame index as a column\n",
    "\n",
    "#They are not marked in any way so they are just random pieces of information\n",
    "#Need to find a way to associate either the post title or the post URL with the post comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa5d633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebed2a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating weights for each embedding based on score values, plugging them into a tuned sigmoid function\n",
    "# 0-200 has factor ~1, 200-500 has factor ~1.3, 500-700 has factor ~1.6, 700+ has factor ~1.8\n",
    "# Doesn't function well, need to include comment score scaling as well if implemented\n",
    "\n",
    "# consulting_club_posts['Score Factor'] = consulting_club_posts['Score'].apply(lambda x: 1 + 1/(1+20*pow(2, -x/100)))\n",
    "\n",
    "# consulting_club_posts['Weighted embedding'] = consulting_club_posts['embedding'].combine(consulting_club_posts['Score Factor'], lambda lst, weight: [weight * x for x in lst])\n",
    "# print(consulting_club_posts['Weighted embedding'], consulting_club_posts['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1478f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    dot_prod = sum([x * y for x, y in zip(a, b)])\n",
    "    mag_a = pow(sum([pow(x, 2) for x in a]), 0.5)\n",
    "    mag_b = pow(sum([pow(y, 2) for y in b]), 0.5)\n",
    "    return mag_a * mag_b and (dot_prod) / (mag_a * mag_b)   # add mag_b to dot_prod for weightage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aeffa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(query, n=5):\n",
    "    query_embed = ollama.embed(model=embed_model, input=query)['embeddings']\n",
    "    similarities = consulting_club_posts['embedding'].apply(lambda x: cosine_similarity(query_embed[0], x))     # Change to 'weighted embedding' for weightage\n",
    "    pd.concat([similarities, comments_df['embedding'].apply(lambda x: cosine_similarity(query_embed[0], x))])   \n",
    "    return similarities.nlargest(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03140caa",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m input_query = \u001b[38;5;28minput\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mAsk me a question: \u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m retrieved_knowledge = \u001b[43mretrieve_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m instruction_prompt = \u001b[33mf\u001b[39m\u001b[33m'''\u001b[39m\u001b[33mYou are a helpful chatbot aimed to help UC Berkeley students learn about and choose clubs to join.\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33mUse only the following pieces of context to answer the question. Don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt make up any new information:\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m.join([\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconsulting_club_posts.loc[i,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mPost Text\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mi\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mretrieved_knowledge.index])\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33m'''\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(instruction_prompt)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mretrieve_data\u001b[39m\u001b[34m(query, n)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mretrieve_data\u001b[39m(query, n=\u001b[32m5\u001b[39m):\n\u001b[32m      2\u001b[39m     query_embed = ollama.embed(model=embed_model, \u001b[38;5;28minput\u001b[39m=query)[\u001b[33m'\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     similarities = \u001b[43mconsulting_club_posts\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43membedding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embed\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m     \u001b[38;5;66;03m# Change to 'weighted embedding' for weightage\u001b[39;00m\n\u001b[32m      4\u001b[39m     pd.concat([similarities, comments_df[\u001b[33m'\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: cosine_similarity(query_embed[\u001b[32m0\u001b[39m], x))])   \n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m similarities.nlargest(n)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PyProjects/Consulting_Bot/.venv/lib/python3.13/site-packages/pandas/core/series.py:4943\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4810\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4815\u001b[39m     **kwargs,\n\u001b[32m   4816\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4817\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4818\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4819\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4934\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4935\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4936\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4937\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4941\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4942\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4943\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PyProjects/Consulting_Bot/.venv/lib/python3.13/site-packages/pandas/core/apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PyProjects/Consulting_Bot/.venv/lib/python3.13/site-packages/pandas/core/apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PyProjects/Consulting_Bot/.venv/lib/python3.13/site-packages/pandas/core/base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PyProjects/Consulting_Bot/.venv/lib/python3.13/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mretrieve_data.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mretrieve_data\u001b[39m(query, n=\u001b[32m5\u001b[39m):\n\u001b[32m      2\u001b[39m     query_embed = ollama.embed(model=embed_model, \u001b[38;5;28minput\u001b[39m=query)[\u001b[33m'\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     similarities = consulting_club_posts[\u001b[33m'\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: cosine_similarity(\u001b[43mquery_embed\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m, x))     \u001b[38;5;66;03m# Change to 'weighted embedding' for weightage\u001b[39;00m\n\u001b[32m      4\u001b[39m     pd.concat([similarities, comments_df[\u001b[33m'\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: cosine_similarity(query_embed[\u001b[32m0\u001b[39m], x))])   \n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m similarities.nlargest(n)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "input_query = input('Ask me a question: ')\n",
    "retrieved_knowledge = retrieve_data(input_query)\n",
    "\n",
    "\n",
    "instruction_prompt = f'''You are a helpful chatbot aimed to help UC Berkeley students learn about and choose clubs to join.\n",
    "Use only the following pieces of context to answer the question. Don't make up any new information:\n",
    "{'\\n'.join([f' - {consulting_club_posts.loc[i, 'Post Text']}' for i in retrieved_knowledge.index])}\n",
    "'''\n",
    "\n",
    "print(instruction_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7727bf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot response:\n",
      "Here's some general information about the tech-specific consulting clubs at UC Berkeley:\n",
      "\n",
      "* **Berkeley Consulting**: A well-established club that provides consulting services to clients. While it's considered prestigious, getting into it is competitive, and you'll likely need a strong understanding of business and operations.\n",
      "* **Voyager Consulting**: The \"vanguard\" of consulting clubs on campus, known for their innovative approaches and high demand among top companies.\n",
      "* **Venture Strategy Solutions (VSS)**: A highly respected club that focuses on venture capital analysis, strategy, and team management. They're often considered one of the most prestigious consulting clubs at UC Berkeley.\n",
      "\n",
      "To increase your chances of getting into these clubs, consider the following:\n",
      "\n",
      "1. **Genuinely impressive projects**: Many successful consultants start with smaller projects or initiatives that demonstrate their capabilities and values.\n",
      "2. **Strong internship experience**: If you're interested in a particular club, try to highlight any relevant internships or work experiences on your application.\n",
      "3. **Networking**: Attend club info sessions, join clubs, and connect with current members to build relationships and learn more about the opportunities available.\n",
      "4. **Demonstrate skills and knowledge**: Show potential for consulting skills by highlighting transferable courses, projects, or research in computer science.\n",
      "\n",
      "To get into these clubs, you'll typically need:\n",
      "\n",
      "* A strong undergraduate GPA (usually 3.5+)\n",
      "* Relevant coursework, such as:\n",
      "\t+ Computer programming\n",
      "\t+ Data structures\n",
      "\t+ Algorithms\n",
      "\t+ Machine learning\n",
      "\t+ Business and management courses\n",
      "* Experience with consulting tools, such as:\n",
      "\t+ Excel\n",
      "\t+ PowerPoint\n",
      "\t+ Word processing software\n",
      "\t+ Online collaboration platforms\n",
      "\n",
      "To increase your chances of getting into these clubs, make sure to:\n",
      "\n",
      "* Review the club's requirements and application guidelines carefully.\n",
      "* Prepare a strong resume and cover letter that highlights relevant skills and experience.\n",
      "* Attend info sessions or networking events to learn more about the clubs and their opportunities.\n",
      "* Reach out to current members or alumni for guidance and advice.\n",
      "\n",
      "Remember, getting into prestigious consulting clubs takes time, effort, and perseverance. Focus on building your network, demonstrating your skills and knowledge, and applying to multiple clubs to increase your chances of success!"
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "  model=lang_model,\n",
    "  messages=[\n",
    "    {'role': 'system', 'content': instruction_prompt},\n",
    "    {'role': 'user', 'content': input_query},\n",
    "  ],\n",
    "  stream=True,\n",
    ")\n",
    "\n",
    "# print the response from the chatbot in real-time\n",
    "print('Chatbot response:')\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
