{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3fb7615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from typing import List, Dict, Optional\n",
    "from html import unescape\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe14d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "# from praw.models import MoreComments #This import is needed is used only if we want to limit the comments we scrape\n",
    "\n",
    "# #URL to access the app needed to scrape the data off the Berkeley subreddit\n",
    "# # https://www.reddit.com/prefs/apps\n",
    "\n",
    "#This is the tutorial I used to set up the web scraping using PRAW\n",
    "#https://www.geeksforgeeks.org/python/scraping-reddit-using-python/\n",
    "\n",
    "# #PLAN\n",
    "# #Scrape the data off the Berkeley subreddit about consulting clubs\n",
    "# #Organize that data using the pandas library\n",
    "# #Create chatbot that utilizes natural language processing that will give users feedback\n",
    "# #about each consulting club here at Berkeley. \n",
    "\n",
    "reddit_read_only = praw.Reddit(client_id = \"QlBfNfxQ3e_MGP9RkaOQig\",\n",
    "                               client_secret = \"SpLjOwYdQPU4z1wqcXBjVl_7DnUIZg\",\n",
    "                               user_agent = \"Berkeley_Consulting\")\n",
    "\n",
    "subreddit = reddit_read_only.subreddit(\"berkeley\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "178c2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "consulting_posts = subreddit.search('clubs', limit=None)\n",
    "\n",
    "posts_dict = {'Title': [], 'Post Text': [], 'ID': [], 'Score': [], 'Total Comments': [], 'Post URL': []}\n",
    "comments_dict = {'Comment': [], 'Score': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ecf18af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Post Text</th>\n",
       "      <th>ID</th>\n",
       "      <th>Score</th>\n",
       "      <th>Total Comments</th>\n",
       "      <th>Post URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Looking for people to start a bridge troll clu...</td>\n",
       "      <td>Hello, \\n\\nI was wondering if anyone else woul...</td>\n",
       "      <td>1nfcxn2</td>\n",
       "      <td>265</td>\n",
       "      <td>36</td>\n",
       "      <td>https://www.reddit.com/r/berkeley/comments/1nf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heartbreaking club experience as a freshman</td>\n",
       "      <td>I applied to 9 tech clubs (i‚Äôm an eecs major) ...</td>\n",
       "      <td>1nh1egm</td>\n",
       "      <td>131</td>\n",
       "      <td>52</td>\n",
       "      <td>https://www.reddit.com/r/berkeley/comments/1nh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Berkeley club decisions today got me like:</td>\n",
       "      <td>[Berkeley club decisions today got me like:](h...</td>\n",
       "      <td>1na5tea</td>\n",
       "      <td>71</td>\n",
       "      <td>50</td>\n",
       "      <td>https://www.reddit.com/r/berkeley/comments/1na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Potential nepotism in prestigious clubs is sic...</td>\n",
       "      <td>Title. So exhausted of this kinda stuff. Heard...</td>\n",
       "      <td>1nbpwed</td>\n",
       "      <td>108</td>\n",
       "      <td>36</td>\n",
       "      <td>https://www.reddit.com/r/berkeley/comments/1nb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Asian monoculture in consulting clubs</td>\n",
       "      <td>Over the past month on this subreddit there ha...</td>\n",
       "      <td>16o5u8z</td>\n",
       "      <td>268</td>\n",
       "      <td>112</td>\n",
       "      <td>https://www.reddit.com/r/berkeley/comments/16o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>So you got rejected from a club. What now?</td>\n",
       "      <td>So you got rejected by a club at Berkeley. Pro...</td>\n",
       "      <td>sh9utu</td>\n",
       "      <td>161</td>\n",
       "      <td>24</td>\n",
       "      <td>https://www.reddit.com/r/berkeley/comments/sh9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Are there any clubs on campus for students who...</td>\n",
       "      <td>Basically what the title says! Or if there are...</td>\n",
       "      <td>1h0w654</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/berkeley/comments/1h0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>What are some fun clubs on campus?</td>\n",
       "      <td>Anyone have any recommendations?</td>\n",
       "      <td>198ng9e</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>https://www.reddit.com/r/berkeley/comments/198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>How to get into Consulting clubs?</td>\n",
       "      <td>Hello! I'm going to be a sophomore next year a...</td>\n",
       "      <td>1ek2g0a</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>https://www.reddit.com/r/berkeley/comments/1ek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>[Club Recruitment Megathread] Have a club that...</td>\n",
       "      <td>Here is the format you should follow to ensure...</td>\n",
       "      <td>i9yljd</td>\n",
       "      <td>82</td>\n",
       "      <td>46</td>\n",
       "      <td>https://www.reddit.com/r/berkeley/comments/i9y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0    Looking for people to start a bridge troll clu...   \n",
       "1          Heartbreaking club experience as a freshman   \n",
       "2           Berkeley club decisions today got me like:   \n",
       "3    Potential nepotism in prestigious clubs is sic...   \n",
       "4                Asian monoculture in consulting clubs   \n",
       "..                                                 ...   \n",
       "204         So you got rejected from a club. What now?   \n",
       "205  Are there any clubs on campus for students who...   \n",
       "206                 What are some fun clubs on campus?   \n",
       "207                  How to get into Consulting clubs?   \n",
       "208  [Club Recruitment Megathread] Have a club that...   \n",
       "\n",
       "                                             Post Text       ID  Score  \\\n",
       "0    Hello, \\n\\nI was wondering if anyone else woul...  1nfcxn2    265   \n",
       "1    I applied to 9 tech clubs (i‚Äôm an eecs major) ...  1nh1egm    131   \n",
       "2    [Berkeley club decisions today got me like:](h...  1na5tea     71   \n",
       "3    Title. So exhausted of this kinda stuff. Heard...  1nbpwed    108   \n",
       "4    Over the past month on this subreddit there ha...  16o5u8z    268   \n",
       "..                                                 ...      ...    ...   \n",
       "204  So you got rejected by a club at Berkeley. Pro...   sh9utu    161   \n",
       "205  Basically what the title says! Or if there are...  1h0w654      3   \n",
       "206                   Anyone have any recommendations?  198ng9e     14   \n",
       "207  Hello! I'm going to be a sophomore next year a...  1ek2g0a      4   \n",
       "208  Here is the format you should follow to ensure...   i9yljd     82   \n",
       "\n",
       "     Total Comments                                           Post URL  \n",
       "0                36  https://www.reddit.com/r/berkeley/comments/1nf...  \n",
       "1                52  https://www.reddit.com/r/berkeley/comments/1nh...  \n",
       "2                50  https://www.reddit.com/r/berkeley/comments/1na...  \n",
       "3                36  https://www.reddit.com/r/berkeley/comments/1nb...  \n",
       "4               112  https://www.reddit.com/r/berkeley/comments/16o...  \n",
       "..              ...                                                ...  \n",
       "204              24  https://www.reddit.com/r/berkeley/comments/sh9...  \n",
       "205               0  https://www.reddit.com/r/berkeley/comments/1h0...  \n",
       "206              16  https://www.reddit.com/r/berkeley/comments/198...  \n",
       "207               6  https://www.reddit.com/r/berkeley/comments/1ek...  \n",
       "208              46  https://www.reddit.com/r/berkeley/comments/i9y...  \n",
       "\n",
       "[209 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for post in consulting_posts:\n",
    "    if len(post.selftext) > 20:\n",
    "        #The title of the post\n",
    "        posts_dict['Title'].append(post.title)\n",
    "        #The text inside of the post\n",
    "        posts_dict['Post Text'].append(post.selftext)\n",
    "        #Unique ID of each post\n",
    "        posts_dict['ID'].append(post.id)\n",
    "        #The scoure of a post\n",
    "        posts_dict['Score'].append(post.score)\n",
    "        #Total number of comments inside the post\n",
    "        posts_dict['Total Comments'].append(post.num_comments)\n",
    "        #URL of each post\n",
    "        posts_dict['Post URL'].append(post.url)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "consulting_club_posts = pd.DataFrame(posts_dict)\n",
    "# print(consulting_club_posts)\n",
    "consulting_club_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01d1eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don‚Äôt forget riddles</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if you‚Äôre deadass, i will absolutely join</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm actually serious about starting it, if som...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>definitely don‚Äôt go barefoot under a bridge, t...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do we get to eat billy goats?</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>Hi! Student here looking for a club!\\n\\n1. I w...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>**JOIN THE BERKELEY FORUM**\\n\\n1. **All Majors...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>Hi all, we're Berkeley Phi Beta Lambda, a chap...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>Hi Everyone! I'm representing Womxn in Math at...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>Hi, posting for **Berkeley Psychology Group**!...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment  Score\n",
       "0                                  Don‚Äôt forget riddles     67\n",
       "1             if you‚Äôre deadass, i will absolutely join     51\n",
       "2     I'm actually serious about starting it, if som...     49\n",
       "3     definitely don‚Äôt go barefoot under a bridge, t...     16\n",
       "4                         Do we get to eat billy goats?     12\n",
       "...                                                 ...    ...\n",
       "1043  Hi! Student here looking for a club!\\n\\n1. I w...      2\n",
       "1044  **JOIN THE BERKELEY FORUM**\\n\\n1. **All Majors...      2\n",
       "1045  Hi all, we're Berkeley Phi Beta Lambda, a chap...      2\n",
       "1046  Hi Everyone! I'm representing Womxn in Math at...      2\n",
       "1047  Hi, posting for **Berkeley Psychology Group**!...      1\n",
       "\n",
       "[1048 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Need to figure out a way to get the URL of each and every post\n",
    "for i in posts_dict['Post URL']:\n",
    "    if 'comments' in i:\n",
    "        submission = reddit_read_only.submission(url = i)\n",
    "    else:\n",
    "        continue\n",
    "    for comment in submission.comments:\n",
    "        if len(comment.body) < 20:\n",
    "            continue\n",
    "        comments_dict['Comment'].append(comment.body)\n",
    "        comments_dict['Score'].append(comment.score)\n",
    "\n",
    "# print(post_comments[0]) #This only prints one comment right now for one URL. Need to get as many comments as possible for one given URL.\n",
    "\n",
    "comments_df = pd.DataFrame(comments_dict)\n",
    "comments_df\n",
    "\n",
    "#Generate the CSV file that contains all the posts about Berkeley clubs\n",
    "# comments_df.to_csv('my_dataframe.csv', index=False) # index=False prevents writing the DataFrame index as a column\n",
    "\n",
    "#They are not marked in any way so they are just random pieces of information\n",
    "#Need to find a way to associate either the post title or the post URL with the post comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eba06ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post Text</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello, \\n\\nI was wondering if anyone else woul...</td>\n",
       "      <td>Don‚Äôt forget riddles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I applied to 9 tech clubs (i‚Äôm an eecs major) ...</td>\n",
       "      <td>if you‚Äôre deadass, i will absolutely join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Berkeley club decisions today got me like:](h...</td>\n",
       "      <td>I'm actually serious about starting it, if som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Title. So exhausted of this kinda stuff. Heard...</td>\n",
       "      <td>definitely don‚Äôt go barefoot under a bridge, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Over the past month on this subreddit there ha...</td>\n",
       "      <td>Do we get to eat billy goats?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi! Student here looking for a club!\\n\\n1. I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>NaN</td>\n",
       "      <td>**JOIN THE BERKELEY FORUM**\\n\\n1. **All Majors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi all, we're Berkeley Phi Beta Lambda, a chap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi Everyone! I'm representing Womxn in Math at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi, posting for **Berkeley Psychology Group**!...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Post Text  \\\n",
       "0     Hello, \\n\\nI was wondering if anyone else woul...   \n",
       "1     I applied to 9 tech clubs (i‚Äôm an eecs major) ...   \n",
       "2     [Berkeley club decisions today got me like:](h...   \n",
       "3     Title. So exhausted of this kinda stuff. Heard...   \n",
       "4     Over the past month on this subreddit there ha...   \n",
       "...                                                 ...   \n",
       "1043                                                NaN   \n",
       "1044                                                NaN   \n",
       "1045                                                NaN   \n",
       "1046                                                NaN   \n",
       "1047                                                NaN   \n",
       "\n",
       "                                                Comment  \n",
       "0                                  Don‚Äôt forget riddles  \n",
       "1             if you‚Äôre deadass, i will absolutely join  \n",
       "2     I'm actually serious about starting it, if som...  \n",
       "3     definitely don‚Äôt go barefoot under a bridge, t...  \n",
       "4                         Do we get to eat billy goats?  \n",
       "...                                                 ...  \n",
       "1043  Hi! Student here looking for a club!\\n\\n1. I w...  \n",
       "1044  **JOIN THE BERKELEY FORUM**\\n\\n1. **All Majors...  \n",
       "1045  Hi all, we're Berkeley Phi Beta Lambda, a chap...  \n",
       "1046  Hi Everyone! I'm representing Womxn in Math at...  \n",
       "1047  Hi, posting for **Berkeley Psychology Group**!...  \n",
       "\n",
       "[1048 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.concat([consulting_club_posts['Post Text'], comments_df['Comment']], axis=1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e743c4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Loading the stored dataframes from the previous notebook using the pickle module\n",
    "# consulting_club_posts.to_pickle('consulting_club_posts.pkl')\n",
    "# comments_df.to_pickle('comments_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c9c0015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "CalLink Deep Scraper\n",
    "Fetches the organization list AND visits each club's individual page\n",
    "to get comprehensive information\n",
    "\"\"\"\n",
    "\n",
    "def strip_html(text: str) -> str:\n",
    "    \"\"\"Remove HTML tags and clean up text\"\"\"\n",
    "    if not text or not isinstance(text, str):\n",
    "        return ''\n",
    "    \n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = unescape(text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97e7d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_organization_list() -> List[Dict]:\n",
    "    \"\"\"Fetch the list of all organizations from the API\"\"\"\n",
    "    base_url = \"https://callink.berkeley.edu/api/discovery/search/organizations\"\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',\n",
    "        'Accept': 'application/json',\n",
    "        'Referer': 'https://callink.berkeley.edu/Organizations',\n",
    "    }\n",
    "    \n",
    "    all_organizations = []\n",
    "    skip = 0\n",
    "    top = 100\n",
    "    \n",
    "    print(\"üìã Fetching organization list from CalLink API...\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    while True:\n",
    "        params = {\n",
    "            'top': top,\n",
    "            'skip': skip,\n",
    "            'orderBy[0]': 'UpperName asc',\n",
    "            'query': '',\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            print(f\"  Fetching organizations {skip + 1} to {skip + top}...\", end=\" \")\n",
    "            response = requests.get(base_url, params=params, headers=headers, timeout=15)\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                print(f\"‚ùå Error: Status code {response.status_code}\")\n",
    "                break\n",
    "            \n",
    "            data = response.json()\n",
    "            \n",
    "            if isinstance(data, dict):\n",
    "                orgs = data.get('value', data.get('items', data.get('results', [])))\n",
    "            elif isinstance(data, list):\n",
    "                orgs = data\n",
    "            else:\n",
    "                print(\"‚ùå Unexpected response format\")\n",
    "                break\n",
    "            \n",
    "            if not orgs:\n",
    "                print(\"‚úì Done\")\n",
    "                break\n",
    "            \n",
    "            all_organizations.extend(orgs)\n",
    "            print(f\"‚úì Got {len(orgs)} (Total: {len(all_organizations)})\")\n",
    "            \n",
    "            if len(orgs) < top:\n",
    "                break\n",
    "            \n",
    "            skip += top\n",
    "            time.sleep(0.3)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            break\n",
    "    \n",
    "    print(f\"\\n‚úì Found {len(all_organizations)} organizations total\\n\")\n",
    "    return all_organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98667579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_organization_page(org_url: str, org_name: str) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Scrape detailed information from an individual organization page\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(org_url, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        details = {}\n",
    "        \n",
    "        # Try to extract various fields from the page\n",
    "        # These selectors are educated guesses - we'll need to adjust based on actual HTML\n",
    "        \n",
    "        # Description (usually in a main content area)\n",
    "        desc_selectors = [\n",
    "            'div.organization-description',\n",
    "            'div.description',\n",
    "            'div[class*=\"about\"]',\n",
    "            'div[class*=\"description\"]',\n",
    "            'section.description',\n",
    "        ]\n",
    "        for selector in desc_selectors:\n",
    "            elem = soup.select_one(selector)\n",
    "            if elem:\n",
    "                details['full_description'] = strip_html(elem.get_text())\n",
    "                break\n",
    "        \n",
    "        # Purpose/Mission\n",
    "        purpose_selectors = [\n",
    "            'div.purpose',\n",
    "            'div[class*=\"mission\"]',\n",
    "            'div[class*=\"purpose\"]',\n",
    "        ]\n",
    "        for selector in purpose_selectors:\n",
    "            elem = soup.select_one(selector)\n",
    "            if elem:\n",
    "                details['purpose'] = strip_html(elem.get_text())\n",
    "                break\n",
    "        \n",
    "        # Meeting info\n",
    "        meeting_selectors = [\n",
    "            'div.meeting-info',\n",
    "            'div[class*=\"meeting\"]',\n",
    "            'span[class*=\"meeting\"]',\n",
    "        ]\n",
    "        for selector in meeting_selectors:\n",
    "            elem = soup.select_one(selector)\n",
    "            if elem:\n",
    "                details['meeting_info'] = strip_html(elem.get_text())\n",
    "                break\n",
    "        \n",
    "        # Contact email(s)\n",
    "        emails = soup.find_all('a', href=re.compile(r'mailto:'))\n",
    "        if emails:\n",
    "            details['emails'] = ', '.join([e.get('href', '').replace('mailto:', '') for e in emails])\n",
    "        \n",
    "        # Social media links\n",
    "        social_links = {}\n",
    "        social_patterns = {\n",
    "            'facebook': r'facebook\\.com',\n",
    "            'instagram': r'instagram\\.com',\n",
    "            'twitter': r'twitter\\.com|x\\.com',\n",
    "            'linkedin': r'linkedin\\.com',\n",
    "            'discord': r'discord\\.(gg|com)',\n",
    "        }\n",
    "        \n",
    "        for platform, pattern in social_patterns.items():\n",
    "            link = soup.find('a', href=re.compile(pattern))\n",
    "            if link:\n",
    "                social_links[platform] = link.get('href', '')\n",
    "        \n",
    "        if social_links:\n",
    "            details['social_media'] = json.dumps(social_links)\n",
    "        \n",
    "        # Website\n",
    "        website = soup.find('a', href=re.compile(r'^https?://(?!callink\\.berkeley)'))\n",
    "        if website:\n",
    "            details['website'] = website.get('href', '')\n",
    "        \n",
    "        # Try to get all text content as fallback\n",
    "        if not details:\n",
    "            main_content = soup.find('main') or soup.find('body')\n",
    "            if main_content:\n",
    "                details['full_content'] = strip_html(main_content.get_text())\n",
    "        \n",
    "        return details if details else None\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5ebe5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_organizations_detailed(org_list: List[Dict], max_orgs: Optional[int] = None) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Visit each organization's page and collect detailed information\n",
    "    \n",
    "    Args:\n",
    "        org_list: List of organizations from the API\n",
    "        max_orgs: Optional limit for testing (scrape only first N orgs)\n",
    "    \"\"\"\n",
    "    print(\"üîç Scraping detailed information from each organization page...\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if max_orgs:\n",
    "        print(f\"‚ö†Ô∏è  TEST MODE: Only scraping first {max_orgs} organizations\\n\")\n",
    "        org_list = org_list[:max_orgs]\n",
    "    \n",
    "    enriched_orgs = []\n",
    "    failed_count = 0\n",
    "    \n",
    "    for idx, org in enumerate(org_list, 1):\n",
    "        # Get basic info from API response\n",
    "        org_data = {\n",
    "            'name': strip_html(org.get('Name', org.get('name', ''))),\n",
    "            'short_description': strip_html(org.get('Description', org.get('description', ''))),\n",
    "            'status': strip_html(org.get('Status', '')),\n",
    "            'email': org.get('Email', org.get('email', '')),\n",
    "        }\n",
    "        \n",
    "        # Get categories\n",
    "        if 'CategoryNames' in org:\n",
    "            cats = org['CategoryNames']\n",
    "            org_data['categories'] = ', '.join([strip_html(str(c)) for c in cats]) if isinstance(cats, list) else strip_html(str(cats))\n",
    "        \n",
    "        # Build profile URL\n",
    "        website_key = org.get('WebsiteKey', '')\n",
    "        if website_key:\n",
    "            org_data['profile_url'] = f\"https://callink.berkeley.edu/organization/{website_key}\"\n",
    "        else:\n",
    "            org_data['profile_url'] = ''\n",
    "        \n",
    "        # Scrape detailed page\n",
    "        print(f\"[{idx}/{len(org_list)}] {org_data['name'][:50]}...\", end=\" \")\n",
    "        \n",
    "        if org_data['profile_url']:\n",
    "            details = scrape_organization_page(org_data['profile_url'], org_data['name'])\n",
    "            \n",
    "            if details:\n",
    "                org_data.update(details)\n",
    "                print(\"‚úì\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  (basic info only)\")\n",
    "                failed_count += 1\n",
    "        else:\n",
    "            print(\"‚ùå (no URL)\")\n",
    "            failed_count += 1\n",
    "        \n",
    "        enriched_orgs.append(org_data)\n",
    "        \n",
    "        # Be respectful to the server\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        # Progress update every 50 orgs\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"\\n  Progress: {idx}/{len(org_list)} completed ({failed_count} failed)\\n\")\n",
    "    \n",
    "    print(f\"\\n‚úì Completed! Successfully scraped {len(enriched_orgs) - failed_count}/{len(enriched_orgs)} organizations\")\n",
    "    print(f\"  ({failed_count} organizations had limited/no detailed info)\\n\")\n",
    "    \n",
    "    return enriched_orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "248d9ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(orgs: List[Dict], prefix: str = 'callink_complete'):\n",
    "    \"\"\"Save scraped data to CSV and JSON\"\"\"\n",
    "    if not orgs:\n",
    "        print(\"‚ùå No data to save\")\n",
    "        return\n",
    "    \n",
    "    df = pd.DataFrame(orgs)\n",
    "    \n",
    "    # Save CSV\n",
    "    csv_file = f'{prefix}.csv'\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f\"‚úì Saved CSV: {csv_file}\")\n",
    "    \n",
    "    # Save JSON\n",
    "    json_file = f'{prefix}.json'\n",
    "    with open(json_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(orgs, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"‚úì Saved JSON: {json_file}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"üìä DATA SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Total organizations: {len(df)}\")\n",
    "    print(f\"\\nColumns ({len(df.columns)}):\")\n",
    "    for col in df.columns:\n",
    "        non_null = df[col].notna().sum()\n",
    "        pct = (non_null / len(df)) * 100\n",
    "        print(f\"  ‚Ä¢ {col}: {non_null}/{len(df)} ({pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nSample organizations:\")\n",
    "    print(df[['name', 'categories']].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e063b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"üêª BERKELEY CALLINK DEEP SCRAPER\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"This will scrape BOTH the organization list AND each club's page\")\n",
    "    print(\"=\" * 70 + \"\\n\")\n",
    "    \n",
    "    # Step 1: Get organization list\n",
    "    org_list = fetch_organization_list()\n",
    "    \n",
    "    if not org_list:\n",
    "        print(\"‚ùå Failed to fetch organization list\")\n",
    "        return\n",
    "    \n",
    "    # Ask user if they want to test first\n",
    "    print(f\"Found {len(org_list)} organizations.\")\n",
    "    print(\"\\nOptions:\")\n",
    "    print(\"  1. Test mode - scrape first 10 organizations (recommended for testing)\")\n",
    "    print(\"  2. Scrape ALL organizations (will take 10-20 minutes)\")\n",
    "    print()\n",
    "    \n",
    "    # For non-interactive mode, default to test\n",
    "    # In interactive mode, you can uncomment the input() line\n",
    "    # choice = input(\"Enter choice (1 or 2): \").strip()\n",
    "    #***************************************************\n",
    "    #CHANGE THIS TO 1 \n",
    "    choice = \"0\"  # Default to test mode\n",
    "    #***************************************************\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        max_orgs = 10\n",
    "        print(f\"\\nüß™ TEST MODE: Scraping first {max_orgs} organizations\\n\")\n",
    "    else:\n",
    "        max_orgs = None\n",
    "        print(f\"\\nüöÄ FULL MODE: Scraping all {len(org_list)} organizations\\n\")\n",
    "        print(\"‚è±Ô∏è  This will take approximately 10-20 minutes...\")\n",
    "        print(\"    (Visiting ~1000 pages with 0.5s delay between requests)\\n\")\n",
    "    \n",
    "    # Step 2: Scrape detailed info\n",
    "    enriched_orgs = scrape_all_organizations_detailed(org_list, max_orgs=max_orgs)\n",
    "    \n",
    "    # Step 3: Save data\n",
    "    print(\"\\nüíæ Saving data...\")\n",
    "    prefix = 'callink_test' if max_orgs else 'callink_complete'\n",
    "    save_data(enriched_orgs, prefix=prefix)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úÖ SCRAPING COMPLETE!\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if max_orgs:\n",
    "        print(\"\\nüí° TIP: This was a test run. To scrape all organizations,\")\n",
    "        print(\"   change 'choice = \\\"1\\\"' to 'choice = \\\"2\\\"' in the script.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # main()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c7dcbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>club_name</th>\n",
       "      <th>acronym</th>\n",
       "      <th>website</th>\n",
       "      <th>emails</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EECS organizations</td>\n",
       "      <td>The Association of Women in EE &amp; CS</td>\n",
       "      <td>AWE</td>\n",
       "      <td>http://awe.berkeley.edu</td>\n",
       "      <td>aweberkeley@gmail.com;biasbusters-admin@lists....</td>\n",
       "      <td>Formerly AUWICSEE. aweberkeley@gmail.com AWE i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EECS organizations</td>\n",
       "      <td>Blockchain at Berkeley</td>\n",
       "      <td></td>\n",
       "      <td>https://blockchain.berkeley.edu/</td>\n",
       "      <td>admin@blockchain.berkeley.edu</td>\n",
       "      <td>admin@blockchain.berkeley.edu Blockchain at Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EECS organizations</td>\n",
       "      <td>Cloud at Cal</td>\n",
       "      <td></td>\n",
       "      <td>https://sites.google.com/berkeley.edu/cloudatcal</td>\n",
       "      <td>cloudatcal@gmail.com</td>\n",
       "      <td>cloudatcal@gmail.com Cloud at California is UC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EECS organizations</td>\n",
       "      <td>EECS Transfers at Berkeley</td>\n",
       "      <td></td>\n",
       "      <td>https://callink.berkeley.edu/organization/eecs...</td>\n",
       "      <td></td>\n",
       "      <td>EECS Transfers at Berkeley aims to build a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EECS organizations</td>\n",
       "      <td>Eta Kappa Nu (HKN) EECS Honor Society</td>\n",
       "      <td></td>\n",
       "      <td>http://hkn.eecs.berkeley.edu/</td>\n",
       "      <td>hkn@hkn.eecs.berkeley.edu</td>\n",
       "      <td>hkn@hkn.eecs.berkeley.edu Eta Kappa Nu (HKN) i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category                              club_name acronym  \\\n",
       "0  EECS organizations    The Association of Women in EE & CS     AWE   \n",
       "1  EECS organizations                 Blockchain at Berkeley           \n",
       "2  EECS organizations                           Cloud at Cal           \n",
       "3  EECS organizations             EECS Transfers at Berkeley           \n",
       "4  EECS organizations  Eta Kappa Nu (HKN) EECS Honor Society           \n",
       "\n",
       "                                             website  \\\n",
       "0                            http://awe.berkeley.edu   \n",
       "1                   https://blockchain.berkeley.edu/   \n",
       "2   https://sites.google.com/berkeley.edu/cloudatcal   \n",
       "3  https://callink.berkeley.edu/organization/eecs...   \n",
       "4                      http://hkn.eecs.berkeley.edu/   \n",
       "\n",
       "                                              emails  \\\n",
       "0  aweberkeley@gmail.com;biasbusters-admin@lists....   \n",
       "1                      admin@blockchain.berkeley.edu   \n",
       "2                               cloudatcal@gmail.com   \n",
       "3                                                      \n",
       "4                          hkn@hkn.eecs.berkeley.edu   \n",
       "\n",
       "                                         description  \n",
       "0  Formerly AUWICSEE. aweberkeley@gmail.com AWE i...  \n",
       "1  admin@blockchain.berkeley.edu Blockchain at Be...  \n",
       "2  cloudatcal@gmail.com Cloud at California is UC...  \n",
       "3  EECS Transfers at Berkeley aims to build a com...  \n",
       "4  hkn@hkn.eecs.berkeley.edu Eta Kappa Nu (HKN) i...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://eecs.berkeley.edu/people/students-2/organizations/\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/122.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# --- 1. Download page ---\n",
    "resp = requests.get(URL, headers=headers)\n",
    "resp.raise_for_status()\n",
    "html = resp.text\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# --- 2. Helper: find sections we care about ---\n",
    "section_titles = [\n",
    "    \"EECS organizations\",\n",
    "    \"EE organizations\",\n",
    "    \"CS organizations\",\n",
    "]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for section_title in section_titles:\n",
    "    # find the <h2> (or similar) whose text matches the section title\n",
    "    header = soup.find(\n",
    "        lambda tag: tag.name in [\"h2\", \"h3\"]\n",
    "        and tag.get_text(strip=True) == section_title\n",
    "    )\n",
    "    if header is None:\n",
    "        continue\n",
    "\n",
    "    # Walk over siblings until the next h2 (i.e., next big section)\n",
    "    sibling = header.find_next_sibling()\n",
    "    while sibling and sibling.name != \"h2\":\n",
    "        # Each club is under an h3 (or sometimes h4)\n",
    "        if sibling.name in [\"h3\", \"h4\"]:\n",
    "            club_header = sibling\n",
    "\n",
    "            full_title = club_header.get_text(\" \", strip=True)\n",
    "            # Try to pull acronym in parentheses at end of title\n",
    "            m = re.search(r\"\\(([^)]+)\\)\\s*$\", full_title)\n",
    "            acronym = m.group(1) if m else \"\"\n",
    "\n",
    "            # Main club name = title with trailing \"(ABC)\" removed\n",
    "            club_name = full_title\n",
    "            if m:\n",
    "                club_name = full_title[:m.start()].strip(\", \").strip()\n",
    "\n",
    "            # Website = first link in the header, if any\n",
    "            link_tag = club_header.find(\"a\")\n",
    "            website = link_tag[\"href\"] if link_tag and link_tag.has_attr(\"href\") else \"\"\n",
    "\n",
    "            # Collect description + emails from following siblings\n",
    "            desc_parts = []\n",
    "            emails = set()\n",
    "\n",
    "            desc_sib = club_header.find_next_sibling()\n",
    "            while desc_sib and desc_sib.name not in [\"h3\", \"h4\", \"h2\"]:\n",
    "                text = desc_sib.get_text(\" \", strip=True)\n",
    "                if text:\n",
    "                    desc_parts.append(text)\n",
    "\n",
    "                    # find email-like strings in the text\n",
    "                    for email in re.findall(r\"[\\w\\.-]+@[\\w\\.-]+\\.\\w+\", text):\n",
    "                        emails.add(email)\n",
    "\n",
    "                desc_sib = desc_sib.find_next_sibling()\n",
    "\n",
    "            description = \" \".join(desc_parts)\n",
    "\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"category\": section_title,\n",
    "                    \"club_name\": club_name,\n",
    "                    \"acronym\": acronym,\n",
    "                    \"website\": website,\n",
    "                    \"emails\": \";\".join(sorted(emails)),\n",
    "                    \"description\": description,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        sibling = sibling.find_next_sibling()\n",
    "\n",
    "# --- 3. Save to CSV ---\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(\"data/berkeley_eecs_orgs.csv\", index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9be0334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df.to_csv('posts_and_comments.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
